package llm

import (
	"context"

	"github.com/cockroachdb/errors"

	"encore.app/llm/provider"
	"encore.dev/pubsub"
)

// TaskTopic is a topic for tasks generated by the chat service.
// We use a topic to allow for asynchronous processing of tasks (the LLMs can be slow).
//
// This uses Encore's pubsub package, learn more: https://encore.dev/docs/primitives/pubsub
var TaskTopic = pubsub.NewTopic[*provider.ChatRequest]("llm-task", pubsub.TopicConfig{
	DeliveryGuarantee: pubsub.AtLeastOnce,
})

// chat-sub is a subscription to the chat task topic. It handles all incoming tasks from the chat service.
//
// This uses Encore's pubsub package, learn more: https://encore.dev/docs/primitives/pubsub
var _ = pubsub.NewSubscription(
	TaskTopic, "chat-sub",
	pubsub.SubscriptionConfig[*provider.ChatRequest]{
		Handler: pubsub.MethodHandler((*Service).ProcessTask),
	},
)

// ProcessTask processes a task from the chat service by forwarding the request to the appropriate provider.
//
//encore:api private method=POST path=/ai/task
func (svc *Service) ProcessTask(ctx context.Context, req *provider.ChatRequest) error {
	var err error
	switch req.Type {
	case provider.TaskTypeJoin:
		_, err = svc.Introduce(ctx, req)
		if err != nil {
			return errors.Wrap(err, "introduce")
		}
	case provider.TaskTypeContinue:
		_, err = svc.ContinueChat(ctx, req)
		if err != nil {
			return errors.Wrap(err, "continue chat")
		}
	case provider.TaskTypeLeave:
		_, err = svc.Goodbye(ctx, req)
		if err != nil {
			return errors.Wrap(err, "goodbye")
		}
	case provider.TaskTypeInstruct:
		_, err = svc.Instruct(ctx, req)
		if err != nil {
			return errors.Wrap(err, "instruct")
		}
	case provider.TaskTypePrepopulate:
		_, err = svc.Prepopulate(ctx, req)
		if err != nil {
			return errors.Wrap(err, "prepopulate")
		}
	}
	return nil
}
